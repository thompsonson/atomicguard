# AtomicGuard Architecture

This document explains the architectural principles behind AtomicGuard and why they matter for building reliable AI agents.

## Four Aspects

AtomicGuard addresses compounded hallucinations through four complementary aspects:

| Aspect | What It Solves |
|--------|----------------|
| ğŸ›¡ï¸ **Safety** | Errors caught immediately via guard validation |
| ğŸ’¾ **State** | Full context preserved for debugging and resume |
| ğŸŒ **Scale** | Multiple agents without coordination complexity |
| ğŸ“ˆ **Improvement** | System learns from its own failures |

The core principle is **Bounded Indeterminacy**: the LLM generates content, but a deterministic state machine controls the logic. Goals are decomposed into small, measurable tasksâ€”each validated before the workflow advances.

| Layer | Controller | Nature |
|-------|------------|--------|
| **Content** | LLM (Generator) | Stochastic |
| **Logic** | State Machine (Workflow) | Deterministic |
| **Validation** | Guards | Deterministic |

This transforms the problem from:

- âŒ "Hope the agent gets it right" (unbounded search over complex goals)
- âœ… "Ensure each step converges" (bounded validation of small, measurable tasks)

---

## The 4 Aspects in Detail

### ğŸ›¡ï¸ Safety: Atomic Action Pairs

Every generation is wrapped in a **guard transaction**:

```
ActionPair = âŸ¨Generator, GuardâŸ©
```

The workflow state **never advances** unless the guard passes. This is the "atomic" in AtomicGuard:

| Guard Result | Meaning | Action |
|--------------|---------|--------|
| âŠ¤ (pass) | Generation is valid | Advance workflow |
| âŠ¥_retry | Generation failed, recoverable | Retry with feedback |
| âŠ¥_fatal | Unrecoverable failure | Escalate to human |

**Why it matters**: Errors are caught immediately, before they can compound. The workflow state remains clean.

### ğŸ’¾ State: Versioned Environments

Every artifact is stored with its **configuration snapshot**:

```
RepositoryItem = âŸ¨artifact, specification, constraints, workflow_ref, history, sourceâŸ©
```

This enables:

- **Checkpointing**: Pause and resume without losing context
- **Time travel**: Inspect any prior state
- **Reproducibility**: Know exactly what configuration produced each artifact
- **Audit trail**: Track how configuration evolved

**Why it matters**: Treat agent memory like `git`. Every state is recoverable, every change is traceable.

### ğŸŒ Scale: Emergent Coordination

Multiple agents coordinate via a **shared DAG** (Directed Acyclic Graph):

```
Agent A writes â†’ Repository â† Agent B reads
```

This is the **Blackboard Pattern**:

- No message buses or coordination protocols
- Agents read from and write to the shared repository
- One agent's output is another agent's input
- Coordination emerges from the data structure, not explicit communication

**Why it matters**: Scaling to multiple agents doesn't require complex distributed systems infrastructure. The append-only DAG provides natural consistency guarantees.

### ğŸ“ˆ Improvement: The Learning Loop

Every guard verdict is a **training signal**:

| Verdict | Signal |
|---------|--------|
| âŠ¤ (accepted) | Positive example |
| âŠ¥ (rejected) | Negative example with feedback |

The system extracts **Training Traces** from execution history:

- Successful (specification â†’ artifact) pairs for supervised fine-tuning
- Guard feedback for reinforcement learning
- Retry chains showing correction patterns

**Why it matters**: Runtime failure is training data. The system improves from its own mistakes.

---

## How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  WORKFLOW (Deterministic FSM)                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  Step 1: âŸ¨TestGenerator, SyntaxGuardâŸ©                   â”‚â”‚
â”‚  â”‚  Step 2: âŸ¨ImplGenerator, TestGuardâŸ©  [requires: Step 1] â”‚â”‚
â”‚  â”‚  Step 3: âŸ¨DocGenerator, FormatGuardâŸ© [requires: Step 2] â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EXECUTION LOOP (per step)                                  â”‚
â”‚                                                             â”‚
â”‚  1. Generate: artifact â† Generator(context)                â”‚
â”‚  2. Validate: result â† Guard(artifact)                     â”‚
â”‚  3. Branch:                                                 â”‚
â”‚     - âŠ¤: Store artifact, advance to next step              â”‚
â”‚     - âŠ¥_retry: Add feedback to context, retry (up to rmax) â”‚
â”‚     - âŠ¥_fatal: Checkpoint, escalate to human               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  REPOSITORY (Append-only DAG)                               â”‚
â”‚                                                             â”‚
â”‚  All artifacts stored with full context snapshot            â”‚
â”‚  Provenance links track retry chains                        â”‚
â”‚  Enables checkpoint/resume, extraction, learning            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Comparison to Other Approaches

| Approach | How it handles errors | AtomicGuard difference |
|----------|----------------------|------------------------|
| **ReAct** | Retry with reasoning | Guards provide deterministic validation, not just LLM self-reflection |
| **Chain-of-Thought** | Hope reasoning prevents errors | Errors are caught by guards, not hoped away |
| **AutoGPT-style** | Let agent decide next action | Workflow structure is predetermined, only content is generated |
| **LangGraph** | Graph-based workflow | Similar structure, but AtomicGuard adds guard transactions and learning loop |

---

## See Also

- [Paper: Managing the Stochastic](https://arxiv.org/abs/2512.20660) â€” Full formal framework
- [Extensions](extensions/README.md) â€” Formal definitions (Definitions 10-32)
- [Getting Started](../getting-started.md) â€” Quick start guide
- [Decision Log](decisions/decisions.md) â€” Architectural decisions and rationale
